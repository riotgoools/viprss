{"title":"Mediaeater Digest Vol.30, No. 163","link":"https://ghuneim.com/2024/06/11/mediaeater-digest-vol-30-no-163/","date":1718102316000,"content":"<p><a href=\"https://stackdiary.com/meta-says-european-data-is-essential-for-culturally-relevant-ai/\">Meta says European data is essential for culturally relevant AI</a> (stackdiary) Meta says it wants to “push to develop AI that understands and reflects European cultures, languages, and humor,” which sounds promising on the surface. However, the approach</p>\n<p><a href=\"https://www.pnas.org/doi/full/10.1073/pnas.2317967121\">Deception abilities emerged in large language models</a> (pnas) This study unravels a concerning capability in Large Language Models (LLMs): the ability to understand and induce deception strategies. As LLMs like GPT-4 intertwine with human communication, aligning them with human values becomes paramount. The paper demonstrates LLMs’ potential to create false beliefs in other agents within deception scenarios, highlighting a critical need for ethical considerations in the ongoing development and deployment of such advanced AI systems. (seems impt -ed)</p>\n<p><a href=\"https://security.apple.com/blog/private-cloud-compute/\"><span>Private Cloud Compute: A new frontier for AI privacy in the cloud</span></a><span> (apple.com) </span><span><a href=\"https://www.apple.com/apple-intelligence\">Apple Intelligence</a> is the personal intelligence system that brings powerful generative models to iPhone, iPad, and Mac. For advanced features that need to reason over complex data with larger foundation models, we created Private Cloud Compute (PCC), a groundbreaking cloud intelligence system designed specifically for private AI processing. For the first time ever, Private Cloud Compute extends the industry-leading security and privacy of Apple devices into the cloud, making sure that personal user data sent to PCC isn’t accessible to anyone other than the user — not even to Apple. </span></p>\n<p><a href=\"https://machinelearning.apple.com/research/introducing-apple-foundation-models\"><span>Apple’s On-Device and Server Foundation Models</span></a><span> (machinelearning.apple.com) We protect our users’ privacy with powerful on-device processing and groundbreaking infrastructure like Private Cloud Compute. We do not use our users’ private personal data or user interactions when training our foundation models.</span></p>\n<p><a href=\"https://developer.apple.com/documentation/virtualization/using_icloud_with_macos_virtual_machines?language=objc\"><span>MacOS Sequoia to Allow iCloud Logins in Virtual Machines on ARM Macs</span></a><span> (developer.apple.com) If someone moves a VM to a different Mac host and restarts it, the Virtualization framework automatically creates a new identity for the VM using the information from the Secure Enclave of the new Mac host. This identity change requires the person using the VM to reauthenticate to allow iCloud to restart syncing data to the VM.</span></p>\n<p><a href=\"https://www.oneusefulthing.org/p/what-apples-ai-tells-us-experimental\">What Apple’s AI Tells Us: Experimental Models⁴</a> While Apple is building narrow AI systems that can accurately answer questions about your personal data (“tell me when my mother is landing”), OpenAI wants to build autonomous agents that would complete complex tasks for you (“You know those emails about the new business I want to start, could you figure out what I should do to register it so that it is best for my taxes and do that.”). The first is, as Apple demonstrated, science fact, while the second is science fiction, at least for now.</p>\n<p> </p>\n<p>(this digest progress)</p>","author":"MDG","siteTitle":"Mark Ghuneim","siteHash":"fbdbfb355dab5247b3a3d9c04401313e99252873a1ae0fb1ea729c2e5736c6f3","entryHash":"3d6f6c81291d223e212c4d7524090542fe4a2c2b3d269586713bd69ebbedfb50","category":"default"}