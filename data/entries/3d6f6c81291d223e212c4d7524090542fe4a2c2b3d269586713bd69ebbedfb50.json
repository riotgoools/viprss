{"title":"Mediaeater Digest Vol.30, No. 163","link":"https://ghuneim.com/2024/06/11/mediaeater-digest-vol-30-no-163/","date":1718102316000,"content":"<p><a href=\"https://www.nytimes.com/2024/06/10/technology/california-ai-regulation.html\">Mastercard Launches Its Biometric Retail Payment System in Europe, Using Poland As a Testing Ground</a> (naked capitalism) Mastercard’s global Biometric Checkout Program, represents a first-of-its-kind technology framework to help establish standards for new ways to pay, allowing cardholders to use a wide range of biometric payment authentication methods such as palm, face or iris scan. This simplifies the checkout process in store, as consumers no longer need to use a physical payment card, cash or a mobile device to pay for purchases. With Mastercard Biometric Checkout Program, secure and convenient experiences are possible simply by using your biometrics.</p>\n<p><a href=\"https://www.nytimes.com/2024/06/10/technology/california-ai-regulation.html\">States Take Up A.I. Regulation Amid Federal Standstill</a> (nyt) State lawmakers across the country have proposed nearly 400 new laws on A.I. in recent months, according to the lobbying group TechNet. California leads the states with a total of 50 bills proposed, although that number has narrowed as the legislative session proceeds.  (ed note- don’t worry – they will get it done like ad-tech, privacy, social media and other key regulations – dripping sarcasm)</p>\n<p><a href=\"https://stackdiary.com/meta-says-european-data-is-essential-for-culturally-relevant-ai/\">Meta says European data is essential for culturally relevant AI</a> (stackdiary) Meta says it wants to “push to develop AI that understands and reflects European cultures, languages, and humor,” which sounds promising on the surface. However, the approach</p>\n<p><a href=\"https://www.pnas.org/doi/full/10.1073/pnas.2317967121\">Deception abilities emerged in large language models</a> (pnas) This study unravels a concerning capability in Large Language Models (LLMs): the ability to understand and induce deception strategies. As LLMs like GPT-4 intertwine with human communication, aligning them with human values becomes paramount. The paper demonstrates LLMs’ potential to create false beliefs in other agents within deception scenarios, highlighting a critical need for ethical considerations in the ongoing development and deployment of such advanced AI systems. (seems impt -ed)</p>\n<p><a href=\"https://botharetrue.substack.com/p/what-does-your-stupid-art-even-do-73f\">What does your stupid art even do for the world? </a>(both are true) this George Saunders quote…One thing in our favor: some of this “becoming kinder” happens naturally, with age. It might be a simple matter of attrition: as we get older, we come to see how useless it is to be selfish — how illogical, really. We come to love other people and are thereby counter-instructed in our own centrality.</p>\n<p><a href=\"https://security.apple.com/blog/private-cloud-compute/\"><span>Private Cloud Compute: A new frontier for AI privacy in the cloud</span></a><span> (apple.com) </span><span><a href=\"https://www.apple.com/apple-intelligence\">Apple Intelligence</a> is the personal intelligence system that brings powerful generative models to iPhone, iPad, and Mac. For advanced features that need to reason over complex data with larger foundation models, we created Private Cloud Compute (PCC), a groundbreaking cloud intelligence system designed specifically for private AI processing. For the first time ever, Private Cloud Compute extends the industry-leading security and privacy of Apple devices into the cloud, making sure that personal user data sent to PCC isn’t accessible to anyone other than the user — not even to Apple. </span></p>\n<p><a href=\"https://machinelearning.apple.com/research/introducing-apple-foundation-models\"><span>Apple’s On-Device and Server Foundation Models</span></a><span> (machinelearning.apple.com) We protect our users’ privacy with powerful on-device processing and groundbreaking infrastructure like Private Cloud Compute. We do not use our users’ private personal data or user interactions when training our foundation models.</span></p>\n<p><a href=\"https://developer.apple.com/documentation/virtualization/using_icloud_with_macos_virtual_machines?language=objc\"><span>MacOS Sequoia to Allow iCloud Logins in Virtual Machines on ARM Macs</span></a><span> (developer.apple.com) If someone moves a VM to a different Mac host and restarts it, the Virtualization framework automatically creates a new identity for the VM using the information from the Secure Enclave of the new Mac host. This identity change requires the person using the VM to reauthenticate to allow iCloud to restart syncing data to the VM.</span></p>\n<p><a href=\"https://www.oneusefulthing.org/p/what-apples-ai-tells-us-experimental\">What Apple’s AI Tells Us: Experimental Models⁴</a> While Apple is building narrow AI systems that can accurately answer questions about your personal data (“tell me when my mother is landing”), OpenAI wants to build autonomous agents that would complete complex tasks for you (“You know those emails about the new business I want to start, could you figure out what I should do to register it so that it is best for my taxes and do that.”). The first is, as Apple demonstrated, science fact, while the second is science fiction, at least for now.</p>\n<p> </p>\n<p>(this digest in progress)</p>","author":"MDG","siteTitle":"Mark Ghuneim","siteHash":"fbdbfb355dab5247b3a3d9c04401313e99252873a1ae0fb1ea729c2e5736c6f3","entryHash":"3d6f6c81291d223e212c4d7524090542fe4a2c2b3d269586713bd69ebbedfb50","category":"default"}