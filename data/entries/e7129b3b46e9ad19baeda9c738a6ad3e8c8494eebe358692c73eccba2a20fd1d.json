{"title":"OpenAI Co-Founder Launches New Startup","link":"https://om.co/2024/06/19/openai-co-founder-launches-new-startup/","date":1718842968000,"content":"<p>It might as well be an episode from “Days<em> of Our (AI) Lives</em>. Ilya Sutskever, co-founder of OpenAI, who left the company earlier this spring, is back in action with a new startup, Safe Superintelligence (SSI). Daniel Gross, former AI lead at Apple, and researcher Daniel Levy are co-founders of the company.</p>\n\n\n\n<p>Sutskever is a well-respected and revered researcher who was part of Geoffrey Hinton’s core research group and also at Google. His exit from OpenAI was closely followed. Bloomberg, which<a href=\"https://archive.is/HJMkY\" target=\"_blank\"> first reported the news, is scant on details </a>about the what and how of the company. What does “safe” mean when it comes to superintelligence? Sutskever cryptically explains:</p>\n\n\n\n<blockquote>\n<p>“By safe, we mean safe like nuclear safety as opposed to safe as in ‘trust and safety.'”</p>\n</blockquote>\n\n\n\n<p>On SSI’s company website, the three co-founders <a href=\"https://ssi.inc\">write</a>:</p>\n\n\n\n<blockquote>\n<p>We approach safety and capabilities in tandem, as technical problems to be solved through revolutionary engineering and scientific breakthroughs. We plan to advance capabilities as fast as possible while making sure our safety always remains ahead. This way, we can scale in peace. Our singular focus means no distraction by management overhead or product cycles, and our business model means safety, security, and progress are all insulated from short-term commercial pressures.</p>\n</blockquote>\n\n\n\n<p>I have read fewer word<em>s</em> that have more clarity.</p>\n\n\n\n<p>You might remember Ilya as a key player in the OpenAI board-led ouster of Sam Altman as chief executive officer. Later, he reversed course, faded into the background, and eventually left OpenAI. He wasn’t quite thrilled with the direction of OpenAI, which is looking to scrap its egalitarian roots for a more capitalistic model. The new startup seems to correct some of the sins of OpenAI, that is if you read between the lines.</p>\n\n\n\n<blockquote>\n<p>“This company is special in that its first product will be the safe superintelligence, and it will not do anything else up until then. It will be fully insulated from the outside pressures of having to deal with a large and complicated product and having to be stuck in a competitive rat race.”</p>\n\n\n\n<p>Sutskever, in an interview with<a target=\"_blank\" href=\"https://www.bloomberg.com/news/articles/2024-06-19/openai-co-founder-plans-new-ai-focused-research-lab\"> Bloomberg</a>.</p>\n</blockquote>\n\n\n\n<p>This positioning is interesting and curious, though I agree that “super intelligence” isn’t a business opportunity. It’s likely more about power and control, and monetary gains are a byproduct. It should be interesting to follow SSI’s journey ahead, and how it competes with not only OpenAI but also with Google, Anthropic, and a slew of others coming out of China. </p>\n\n\n\n<p><em>June 19, 2024. San Francisco. </em></p>\n\n\n\n<p></p>","author":"Om Malik","siteTitle":"Om Malik","siteHash":"56aa7c22de1a9e5680d03082a2a13db78fe214c96b8119e8d54042cbf2d355ae","entryHash":"e7129b3b46e9ad19baeda9c738a6ad3e8c8494eebe358692c73eccba2a20fd1d","category":"default"}