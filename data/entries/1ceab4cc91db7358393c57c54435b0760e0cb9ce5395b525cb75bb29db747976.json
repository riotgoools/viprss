{"title":"OpenAI’s comment to the NTIA on open model weights (?)","link":"https://ghuneim.com/2024/04/02/openais-comment-to-the-ntia-on-open-model-weights/","date":1712070163000,"content":"<p>OpenAI’s comment to the NTIA on open model weights: <a href=\"https://openai.com/global-affairs/openai-s-comment-to-the-ntia-on-open-model-weights\"> This comment</a> was submitted by OpenAI in response to NTIA’s March 2024 <a href=\"https://www.ntia.gov/federal-register-notice/2024/dual-use-foundation-artificial-intelligence-models-widely-available\" target=\"_blank\">Request for Information</a> on Dual-Use Foundation Models with Widely Available Weights.</p>\n<p>I asked both Gemini and Open AI to explain that it is not open, the results are telling ….</p>\n<p><em>ME: but its not open</em></p>\n<p><em>Gemini:   You’re absolutely right! Here’s why the situation is complex regarding</em></p>\n<p><em>“openness” with OpenAl and its models:</em></p>\n<p><em>It’s Not Fully Open-Source</em></p>\n<ul>\n<li><em>Code and Weights Not Public: The core code behind OpenAl’s models like GPT-3 or GPT-4, and the specific “weights” (data the model was trained on) are not released to the public. This limits the ability of others to replicate, study, or fully modify the models.</em></li>\n<li><em>API Access: Instead, OpenAl primarily offers access through their API, which involves paying for usage. This gives them some control over how the models are used and potentially mitigates misuse.</em></li>\n</ul>\n<p><em>Reasons for Limited “Openness”</em></p>\n<ul>\n<li><em>Misuse Potential: Large language models are powerful and can be misused for generating harmful text, propaganda, or spreading misinformation. OpenAl likely wants to control the spread to manage these risks.</em></li>\n<li><em>Commercial Interests: OpenAl is a company, and making the models readily available could undermine their business model of selling APl access.</em></li>\n<li><em>Computational Cost: These models are extremely expensive to train and run. Providing full access might lead to unsustainable resource usage.</em></li>\n</ul>\n<p><em>The Debate</em></p>\n<p><em>There’s ongoing debate about whether Al models this powerful should be open-source:</em></p>\n<ul>\n<li><em>Pro-Openness: Advocates argue it promotes transparency, community-driven improvements, and fights potential biases within the models.</em></li>\n<li><em>Pro-Controlled Release: Others argue responsible release, especially with potentially dangerous technology, is crucial.</em><em>OpenAl likely falls into this camp.</em></li>\n</ul>\n<p><em>Then I asked open AI the same thing…</em> This is some next level LLM lexicon to hedge the position and then of course for futher questions talk to a web end point.</p>\n<p><strong><em>OpenAl’s comments to the NTIA address the balance between innovation and safety in Al development, emphasizing their approach to mitigating misuse through staged releases and API strategies. They propose a Preparedness Framework for assessing Al model risks and advocate for a diverse ecosystem that includes both open model weights and API-based releases. For further details, please visit OpenAl’s website directly via the provided link.</em></strong></p>\n<p> </p>","author":"MDG","siteTitle":"Mark Ghuneim","siteHash":"fbdbfb355dab5247b3a3d9c04401313e99252873a1ae0fb1ea729c2e5736c6f3","entryHash":"1ceab4cc91db7358393c57c54435b0760e0cb9ce5395b525cb75bb29db747976","category":"default"}