{"title":"A new paper on the economics of AI alignment","link":"https://feeds.feedblitz.com/~/909347030/0/marginalrevolution~A-new-paper-on-the-economics-of-AI-alignment.html","date":1734117035000,"content":"<blockquote><p>A principal wants to deploy an artificial intelligence (AI) system to perform some task. But the AI may be misaligned and pursue a conflicting objective. The principal cannot restrict its options or deliver punishments. Instead, the principal can (i) simulate the task in a testing environment and (ii) imposeÂ <em>imperfect recall</em>Â on the AI, obscuring whether the task being performed is real or part of a test. By committing to a testing mechanism, the principal canÂ <em>screen</em>Â the misaligned AI during testing andÂ <em>discipline</em>Â its behaviour in deployment. Increasing the number of tests allows the principal to screen or discipline arbitrarily well. The screening effect is preserved even if the principal cannot commit or if the agent observes information partially revealing the nature of the task. Without commitment, imperfect recall is necessary for testing to be helpful.</p></blockquote>\r\n<p><a href=\"https://feeds.feedblitz.com/~/t/0/0/marginalrevolution/~https://globalprioritiesinstitute.org/imperfect-recall-and-ai-delegation-chen-ghersengorin-and-petersen/\" target=\"_blank\">That</a> is by Eric Olav Chen, Alexis Ghersengorin, and Sami Petersen.Â  And here is <a href=\"https://feeds.feedblitz.com/~/t/0/0/marginalrevolution/~https://x.com/SamiCPetersen/status/1867203935616053353\" target=\"_blank\">a tweet storm on the paper</a>.Â  I am very glad to see the idea of an optimal principal-agent contract brought more closely into AI alignment discussions.Â  As you can see, it tends to make successful alignment more likely.</p>\r\n<p>The post <a href=\"https://feeds.feedblitz.com/~/t/0/0/marginalrevolution/~https://marginalrevolution.com/marginalrevolution/2024/12/a-new-paper-on-the-economics-of-ai-alignment.html\">A new paper on the economics of AI alignment</a> appeared first on <a href=\"https://feeds.feedblitz.com/~/t/0/0/marginalrevolution/~https://marginalrevolution.com\">Marginal REVOLUTION</a>.</p>\r\n<img height=\"1\" width=\"1\" src=\"https://feeds.feedblitz.com/~/i/909347030/0/marginalrevolution\" />\r\n<div><a href=\"https://feeds.feedblitz.com/_/28/909347030/marginalrevolution\"><img height=\"20\" src=\"https://assets.feedblitz.com/i/fblike20.png\" /></a>Â <a href=\"https://feeds.feedblitz.com/_/29/909347030/marginalrevolution,\"><img height=\"20\" src=\"https://assets.feedblitz.com/i/pinterest20.png\" /></a>Â <a href=\"https://feeds.feedblitz.com/_/24/909347030/marginalrevolution\"><img height=\"20\" src=\"https://assets.feedblitz.com/i/x.png\" /></a>Â <a href=\"https://feeds.feedblitz.com/_/19/909347030/marginalrevolution\"><img height=\"20\" src=\"https://assets.feedblitz.com/i/email20.png\" /></a>Â <a href=\"https://feeds.feedblitz.com/_/20/909347030/marginalrevolution\"><img height=\"20\" src=\"https://assets.feedblitz.com/i/rss20.png\" /></a>Â <a href=\"https://marginalrevolution.com/marginalrevolution/2024/12/a-new-paper-on-the-economics-of-ai-alignment.html#comments\"><img height=\"20\" src=\"https://assets.feedblitz.com/i/comments20.png\" /></a>Â <a href=\"https://marginalrevolution.com/marginalrevolution/2024/12/a-new-paper-on-the-economics-of-ai-alignment.html/feed\"><img height=\"20\" src=\"https://assets.feedblitz.com/i/commentsrss20.png\" /></a>Â \r\n<div><a href=\"https://marginalrevolution.com/marginalrevolution/2024/12/a-new-paper-on-the-economics-of-ai-alignment.html#comments\"><h3>Comments</h3></a><ul><li><a href=\"https://marginalrevolution.com/marginalrevolution/2024/12/a-new-paper-on-the-economics-of-ai-alignment.html#comment-160846199\">In reply to mento.   Hoo hootooloo!!! ğŸ˜†</a> <i>by Hoo hootooloo!</i></li><li><a href=\"https://marginalrevolution.com/marginalrevolution/2024/12/a-new-paper-on-the-economics-of-ai-alignment.html#comment-160846176\">Affirmative action for AI. This is hilarious. Defining failure ...</a> <i>by rayward</i></li><li><a href=\"https://marginalrevolution.com/marginalrevolution/2024/12/a-new-paper-on-the-economics-of-ai-alignment.html#comment-160846172\">In reply to Vulcidian.   The difference is that LLMs are ...</a> <i>by Stephen Wiley</i></li><li><a href=\"https://marginalrevolution.com/marginalrevolution/2024/12/a-new-paper-on-the-economics-of-ai-alignment.html#comment-160846169\">In reply to Horoscopowitz.   â€œI'm afraid. I'm afraid, Dave.â€</a> <i>by Pshrnk</i></li><li><a href=\"https://marginalrevolution.com/marginalrevolution/2024/12/a-new-paper-on-the-economics-of-ai-alignment.html#comment-160846164\">Comments are back to normal</a> <i>by labrigo</i></li><li><a href=\"https://marginalrevolution.com/marginalrevolution/2024/12/a-new-paper-on-the-economics-of-ai-alignment.html#comments\">Plus 10 more...</a></li></ul></div><h3>Related Stories</h3><ul><li><a href=\"https://marginalrevolution.com/marginalrevolution/2024/12/health-insurance-companies-are-not-the-main-villain.html?utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=health-insurance-companies-are-not-the-main-villain\">Health insurance companies are not the main villain</a></li><li><a href=\"https://marginalrevolution.com/marginalrevolution/2024/12/tabarrok-on-bail-2.html?utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=tabarrok-on-bail-2\">Tabarrok on Bail</a></li><li><a href=\"https://marginalrevolution.com/marginalrevolution/2024/12/should-crypto-receive-a-tax-exemption.html?utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=should-crypto-receive-a-tax-exemption\">Should crypto receive a tax exemption?</a></li></ul>Â </div>","author":"Tyler Cowen","siteTitle":"Marginal Revolution","siteHash":"242a3a39129b36e0c574c3796ca7ef3cf8af967286c2998fabf7240d1ad52a47","entryHash":"e41f0b9449f44e0c19f4418c61709594cf350c95be1b1f500f3878be7c1addd5","category":"Sites"}