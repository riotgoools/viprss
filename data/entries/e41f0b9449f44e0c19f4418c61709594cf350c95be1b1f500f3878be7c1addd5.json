{"title":"A new paper on the economics of AI alignment","link":"https://feeds.feedblitz.com/~/909347030/0/marginalrevolution~A-new-paper-on-the-economics-of-AI-alignment.html","date":1734117035000,"content":"<blockquote><p>A principal wants to deploy an artificial intelligence (AI) system to perform some task. But the AI may be misaligned and pursue a conflicting objective. The principal cannot restrict its options or deliver punishments. Instead, the principal can (i) simulate the task in a testing environment and (ii) impose <em>imperfect recall</em> on the AI, obscuring whether the task being performed is real or part of a test. By committing to a testing mechanism, the principal can <em>screen</em> the misaligned AI during testing and <em>discipline</em> its behaviour in deployment. Increasing the number of tests allows the principal to screen or discipline arbitrarily well. The screening effect is preserved even if the principal cannot commit or if the agent observes information partially revealing the nature of the task. Without commitment, imperfect recall is necessary for testing to be helpful.</p></blockquote>\r\n<p><a href=\"https://feeds.feedblitz.com/~/t/0/0/marginalrevolution/~https://globalprioritiesinstitute.org/imperfect-recall-and-ai-delegation-chen-ghersengorin-and-petersen/\" target=\"_blank\">That</a> is by Eric Olav Chen, Alexis Ghersengorin, and Sami Petersen.  And here is <a href=\"https://feeds.feedblitz.com/~/t/0/0/marginalrevolution/~https://x.com/SamiCPetersen/status/1867203935616053353\" target=\"_blank\">a tweet storm on the paper</a>.  I am very glad to see the idea of an optimal principal-agent contract brought more closely into AI alignment discussions.  As you can see, it tends to make successful alignment more likely.</p>\r\n<p>The post <a href=\"https://feeds.feedblitz.com/~/t/0/0/marginalrevolution/~https://marginalrevolution.com/marginalrevolution/2024/12/a-new-paper-on-the-economics-of-ai-alignment.html\">A new paper on the economics of AI alignment</a> appeared first on <a href=\"https://feeds.feedblitz.com/~/t/0/0/marginalrevolution/~https://marginalrevolution.com\">Marginal REVOLUTION</a>.</p>\r\n<img height=\"1\" width=\"1\" src=\"https://feeds.feedblitz.com/~/i/909347030/0/marginalrevolution\" />\r\n<div><a href=\"https://feeds.feedblitz.com/_/28/909347030/marginalrevolution\"><img height=\"20\" src=\"https://assets.feedblitz.com/i/fblike20.png\" /></a> <a href=\"https://feeds.feedblitz.com/_/29/909347030/marginalrevolution,\"><img height=\"20\" src=\"https://assets.feedblitz.com/i/pinterest20.png\" /></a> <a href=\"https://feeds.feedblitz.com/_/24/909347030/marginalrevolution\"><img height=\"20\" src=\"https://assets.feedblitz.com/i/x.png\" /></a> <a href=\"https://feeds.feedblitz.com/_/19/909347030/marginalrevolution\"><img height=\"20\" src=\"https://assets.feedblitz.com/i/email20.png\" /></a> <a href=\"https://feeds.feedblitz.com/_/20/909347030/marginalrevolution\"><img height=\"20\" src=\"https://assets.feedblitz.com/i/rss20.png\" /></a> <a href=\"https://marginalrevolution.com/marginalrevolution/2024/12/a-new-paper-on-the-economics-of-ai-alignment.html#comments\"><img height=\"20\" src=\"https://assets.feedblitz.com/i/comments20.png\" /></a> <a href=\"https://marginalrevolution.com/marginalrevolution/2024/12/a-new-paper-on-the-economics-of-ai-alignment.html/feed\"><img height=\"20\" src=\"https://assets.feedblitz.com/i/commentsrss20.png\" /></a> \r\n<div><a href=\"https://marginalrevolution.com/marginalrevolution/2024/12/a-new-paper-on-the-economics-of-ai-alignment.html#comments\"><h3>Comments</h3></a><ul><li><a href=\"https://marginalrevolution.com/marginalrevolution/2024/12/a-new-paper-on-the-economics-of-ai-alignment.html#comment-160846358\">In reply to rsm.   He did not. He said he lives in California, ...</a> <i>by Serfer Dude</i></li><li><a href=\"https://marginalrevolution.com/marginalrevolution/2024/12/a-new-paper-on-the-economics-of-ai-alignment.html#comment-160846320\">Here's an interesting piece. The BBC is complaining that it is ...</a> <i>by dearieme</i></li><li><a href=\"https://marginalrevolution.com/marginalrevolution/2024/12/a-new-paper-on-the-economics-of-ai-alignment.html#comment-160846243\">Where's the article on the OpenAI whistleblower found dead in ...</a> <i>by MotorCitySounds</i></li><li><a href=\"https://marginalrevolution.com/marginalrevolution/2024/12/a-new-paper-on-the-economics-of-ai-alignment.html#comment-160846242\">I'm a AI. This paper is in my training data, so I know I may be ...</a> <i>by Noumenon72</i></li><li><a href=\"https://marginalrevolution.com/marginalrevolution/2024/12/a-new-paper-on-the-economics-of-ai-alignment.html#comment-160846232\">In reply to N.   What if you inputs end up being something you ...</a> <i>by rsm</i></li><li><a href=\"https://marginalrevolution.com/marginalrevolution/2024/12/a-new-paper-on-the-economics-of-ai-alignment.html#comments\">Plus 10 more...</a></li></ul></div><h3>Related Stories</h3><ul><li><a href=\"https://marginalrevolution.com/marginalrevolution/2024/12/ilyas-talk.html?utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=ilyas-talk\">Ilya’s talk</a></li><li><a href=\"https://marginalrevolution.com/marginalrevolution/2024/12/health-insurance-companies-are-not-the-main-villain.html?utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=health-insurance-companies-are-not-the-main-villain\">Health insurance companies are not the main villain</a></li><li><a href=\"https://marginalrevolution.com/marginalrevolution/2024/12/tabarrok-on-bail-2.html?utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=tabarrok-on-bail-2\">Tabarrok on Bail</a></li></ul> </div>","author":"Tyler Cowen","siteTitle":"Marginal Revolution","siteHash":"242a3a39129b36e0c574c3796ca7ef3cf8af967286c2998fabf7240d1ad52a47","entryHash":"e41f0b9449f44e0c19f4418c61709594cf350c95be1b1f500f3878be7c1addd5","category":"Sites"}