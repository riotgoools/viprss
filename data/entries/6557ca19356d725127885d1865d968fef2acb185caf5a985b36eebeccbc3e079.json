{"title":"On device","link":"https://ghuneim.com/2024/05/21/on-device/","date":1716290910000,"content":"<p>When Google announces it can monitor phone conversations for hostile scams, and Microsoft claims it can search everything you’ve ever touched on your computer, the importance of on-device AI becomes clear. Apple is likely to unveil their own on-device AI capabilities at their upcoming developer event, solidifying this trend.</p>\n<p>The question is, how much of this AI processing will truly stay on-device? Will learnings, user preferences always remain local? It’s crucial to understand the implications of on-device AI for personal OPESEC.</p>\n<p>On-device AI can be more nuanced.  Some examples,,,</p>\n<ol>\n<li>\n<p><strong>Model Updates:</strong> While the AI model itself runs on your device, updates to that model might be downloaded from external servers. These updates could include new features, improved accuracy, or bug fixes.</p>\n</li>\n<li>\n<p><strong>Anonymized Data:</strong> Some on-device AI systems may collect anonymized data about usage patterns or performance to help developers improve the model. This data is stripped of personally identifiable information before being sent.</p>\n</li>\n<li>\n<p><strong>User Consent:</strong> Certain applications might request your permission to share specific data for specific purposes, even with an on-device AI model. For example, a voice assistant might ask to send your voice commands to a server for better speech recognition.</p>\n</li>\n<li>\n<p><strong>Hybrid Models:</strong> Some AI systems use a combination of on-device and cloud-based processing. In these cases, certain parts of the AI model might run on your device, while others rely on external servers for more computationally intensive tasks.</p>\n</li>\n</ol>\n<p><strong>Whats possible now</strong>,  <em>(or what should always be local, and if not, ask why?)</em></p>\n<p><a href=\"https://ghuneim.com/wp-content/uploads/2024/05/Screenshot-2024-05-21-at-7.24.42 AM.png\"><img src=\"https://ghuneim.com/wp-content/uploads/2024/05/Screenshot-2024-05-21-at-7.24.42 AM.png\" width=\"443\" height=\"201\" /></a></p>\n<p>Optimist in me says –  Most important trend done correctly, solves for latency, keeps works offline, keeps data on-device</p>\n<p>Pessimist in me says:  Privacy is always the first victim of connivance,  creep happens and this feature creep will lead to more and more user consent in the guise of utility and convenience.</p>\n<p>I came across this post from Clem at HF summed it up nicely while pointing to four models to use . “- No cloud, no cost, no data sent to anyone, no problem. Welcome to local AI on Hugging Face! ”  Open source FTW</p>","author":"MDG","siteTitle":"Mark Ghuneim","siteHash":"fbdbfb355dab5247b3a3d9c04401313e99252873a1ae0fb1ea729c2e5736c6f3","entryHash":"6557ca19356d725127885d1865d968fef2acb185caf5a985b36eebeccbc3e079","category":"default"}