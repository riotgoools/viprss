{"title":"AI has an “Anus” Problem.","link":"https://om.co/2024/05/24/ai-has-an-anus-problem/","date":1716567394000,"content":"<p>Under pressure from new competitors, Google has added AI summaries to its search results. However, it seems to behaving teething problems. Much of that has to do with the internet information sources Google and other AI services are using. For instance, like OpenAI, Google is using Reddit as a source of data to train its models. It is well known that such conversational platforms have comments that vary from good to garbage. </p>\n\n\n<div>\n<figure><img width=\"1024\" height=\"1006\" src=\"https://149366103.v2.pressablecdn.com/wp-content/uploads/2024/05/IMG_1321-1024x1006.jpeg\" srcset=\"https://149366103.v2.pressablecdn.com/wp-content/uploads/2024/05/IMG_1321-1024x1006.jpeg 1024w, https://149366103.v2.pressablecdn.com/wp-content/uploads/2024/05/IMG_1321-300x295.jpeg 300w, https://149366103.v2.pressablecdn.com/wp-content/uploads/2024/05/IMG_1321-768x754.jpeg 768w, https://149366103.v2.pressablecdn.com/wp-content/uploads/2024/05/IMG_1321-192x189.jpeg 192w, https://149366103.v2.pressablecdn.com/wp-content/uploads/2024/05/IMG_1321-1100x1080.jpeg 1100w, https://149366103.v2.pressablecdn.com/wp-content/uploads/2024/05/IMG_1321-560x550.jpeg 560w, https://149366103.v2.pressablecdn.com/wp-content/uploads/2024/05/IMG_1321.jpeg 1290w\" /></figure></div>\n\n\n<p>Peter Yang <a href=\"https://x.com/petergyang/status/1793480607198323196\">shared one such example on Twitter</a>. When asked how to best stick cheese to pizza, Google AI summary suggested adding glue. That ludicrous suggestion came from an 11-year-old Reddit comment. As I <a href=\"https://om.co/2023/06/21/is-ai-is-a-snake-that-eats-itself/\" target=\"_blank\">had pointed out</a> in an earlier post, we should not be surprised that we are getting “garbage” outputs. It is going to get worse before it gets better. </p>\n\n\n\n<p>This is often the case with technology. I’m fairly certain few remember that nearly a decade ago, Google had to confront an “anus” and “bum” problem. </p>\n\n\n\n<p>Google <a target=\"_blank\" href=\"https://www.npr.org/sections/library/2009/04/the_granting_of_patent_7508978.html\">had developed new</a> OCR software for scanning books into Google Books. Just like the “AI Summaries,” it had bugs — it read “arms” as “anus” and “burn” as “bum” in certain typefaces. There were other such bugs. </p>\n\n\n\n<p>That bug took some of the books in hilarious directions. For instance, here is a quote from John Mackay Wilson’s “<em>Tales of the Borders”</em>: </p>\n\n\n\n<blockquote>\n<p><em>“…poor Janet shuddered at the words which she heard him utter for with strange and wicked oaths he vowed vengeance on the individual who’d persecuted him and she flung her anus around his neck….”</em></p>\n</blockquote>\n\n\n\n<p>Here is another one from “Matisse<em> on the Loose” by Georgina Bragg:</em></p>\n\n\n\n<blockquote>\n<p><em>… “When she spotted me, she flung her anus high in the air and kept them up until she reached me. ‘Matisse. Oh boy!’ she said. She grabbed my anus and positioned my body in the direction of the east gallery and we started walking.”…</em></p>\n</blockquote>\n\n\n\n<p>Google Books’ OCR has always provided great fodder for the literary minded — as so well articulated in this New Yorker article, <a target=\"_blank\" href=\"https://www.newyorker.com/books/page-turner/the-artful-accidents-of-google-books\">The Artful Accident of Google Books</a>. It also inspired its own Tumblr, <a target=\"_blank\" href=\"http://theartofgooglebooks.tumblr.com/\">The Art of Google Books.</a></p>\n\n\n\n<p>Back to the present, like those funny quotes, some of these AI summaries might give us an opportunity to chuckle, but this is no laughing matter. The garbage data will only reinforce more garbage information. </p>\n\n\n\n<p>Given the scale of technology and Google’s influence, the implications of such “mistakes” can be life-threatening. It is not just Google. Open AI is a snake pit of misinformation, <a href=\"https://dl.acm.org/doi/pdf/10.1145/3613904.3642596\">as a group of Purdue University researchers have found</a>. </p>\n\n\n\n<blockquote>\n<p>Our analysis shows that 52% of ChatGPT answers contain incorrect information and 77% are verbose. Nonetheless, our user study participants still preferred ChatGPT answers 35% of the time due to their comprehensiveness and well-articulated language style. However, they also overlooked the misinformation in the ChatGPT answers 39% of the time. This implies the need to counter misinformation in ChatGPT answers to programming questions and raise awareness of the risks associated with seemingly correct answers.</p>\n</blockquote>\n\n\n\n<p>We have entered into a new vortex of information callousness — whose impact we can only understand when looking back at the present. </p>\n\n\n\n<p>May 24, 2024. San Francisco/</p>","author":"Om Malik","siteTitle":"Om Malik","siteHash":"56aa7c22de1a9e5680d03082a2a13db78fe214c96b8119e8d54042cbf2d355ae","entryHash":"006a5b9bc0bc9634d719c70f49c3b0379732cb54fd66770779a28ce6d4c105ad","category":"default"}